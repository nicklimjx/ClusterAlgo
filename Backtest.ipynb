{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f8a4a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from dtaidistance import dtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2d065115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtest:\n",
    "    def __init__(self, csv :str, start :int, interval :int, port) -> None:\n",
    "        self.df = pd.read_csv(csv, delimiter=',')\n",
    "        self.start_idx = self.current_idx = self.df.index[self.df['unix'] == start][0]\n",
    "        self.interval = int(interval / 3600)\n",
    "        self.port = port\n",
    "        self.owned = 0\n",
    "\n",
    "    def get_close(self, datapoints :int):\n",
    "        return self.df.iloc[self.start_idx:self.start_idx + self.interval * datapoints:self.interval]['close']\n",
    "    \n",
    "    def get_price(self):\n",
    "        return self.df.iloc[self.current_idx]['open']\n",
    "\n",
    "    def buy(self, volume: float):\n",
    "            self.owned += volume\n",
    "            self.port -= volume * self.get_price()\n",
    "\n",
    "    def sell(self, volume: float):\n",
    "        if self.owned >= volume:\n",
    "            self.port += volume * self.get_price()\n",
    "            self.owned -= volume\n",
    "        else:\n",
    "            self.port = self.owned * self.get_price()\n",
    "            self.owned = 0\n",
    "\n",
    "    def simple_rsi(self, datapoints :int, lookback=24):\n",
    "        changes = self.get_close(datapoints).pct_change()\n",
    "        simple_rsis = [np.nan]*lookback\n",
    "\n",
    "        for window in changes.rolling(window=lookback):\n",
    "    \n",
    "            if len(window) != lookback: continue\n",
    "\n",
    "            positives = window[window>0].sum()\n",
    "            negatives = window[window<0].sum() * -1\n",
    "\n",
    "            simple_rsis.append(100 - 100/(1 + positives/negatives))\n",
    "\n",
    "        return pd.Series(index = self.get_close(datapoints).index, data=simple_rsis[:-1])\n",
    "    \n",
    "    def get_signals(self, datapoints, buy_thresh: int, sell_thresh: int):\n",
    "        rsi_data = self.simple_rsi(datapoints)\n",
    "        print(f'length of rsi_data is {len(rsi_data)}')\n",
    "        actions = []\n",
    "        for rsi in rsi_data:\n",
    "            if rsi == np.nan: actions.append(None)\n",
    "            \n",
    "            if rsi >= sell_thresh: actions.append('SELL')\n",
    "            elif rsi <= buy_thresh: actions.append('BUY')\n",
    "            else: actions.append(None)\n",
    "        print(f'length of actions is {len(actions)}')\n",
    "        return pd.Series(index=rsi_data.index, data=actions)\n",
    "\n",
    "    def calc_pnl(self):\n",
    "        return self.port + self.owned * self.get_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bc8c1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algo():\n",
    "    ETHUSD = Backtest('BacktestData.csv', 1670396400, 3600*4, 10000)\n",
    "    signals = ETHUSD.get_signals(2000, 35, 65)\n",
    "    k = []\n",
    "    for signal in signals:\n",
    "        if signal == 'BUY' :\n",
    "            ETHUSD.buy(ETHUSD.port/ETHUSD.get_price())\n",
    "        elif signal == 'SELL':\n",
    "            ETHUSD.sell(ETHUSD.owned)\n",
    "        else:\n",
    "            pass\n",
    "        ETHUSD.current_idx += ETHUSD.interval\n",
    "        k.append(ETHUSD.calc_pnl())\n",
    "    print(max(k))\n",
    "    print(ETHUSD.calc_pnl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00b917db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_algo\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_algo' is not defined"
     ]
    }
   ],
   "source": [
    "run_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32404baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data labeling\n",
    "# write + implement dtw\n",
    "# implement kmeans clustering (+ heirarchical clustering as a side bonus?)\n",
    "# cut out outliers from the dataset\n",
    "# create the ml model using indicators (see paper)\n",
    "# train the model (80/20 train test split)\n",
    "# signal generation + final implementation + paper live test?\n",
    "# + finding optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1d9be918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansDTW():\n",
    "    def __init__(self, k: int = 8, max_iter: int = 3000, tol: float = 0.001):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    def create_clusters(self, data: np.ndarray):\n",
    "        # Initialize centroids randomly\n",
    "        rand_idx = np.random.choice(data.shape[0], self.k, replace=False)\n",
    "        self.centroids = data[rand_idx]\n",
    "        \n",
    "        for _ in tqdm(range(self.max_iter)):\n",
    "            self.classifications = [[] for _ in range(self.k)]\n",
    "            \n",
    "            # Precompute distances between each datapoint and each centroid\n",
    "            # This step is assumed to be the optimized part; depending on the fastdtw implementation details\n",
    "            # You might need to manually loop through data and centroids if fastdtw cannot be vectorized directly\n",
    "            for i, datapoint in enumerate(data):\n",
    "                distances = np.array([dtw.distance_fast(centroid, datapoint) for centroid in self.centroids])\n",
    "                closest_centroid_idx = np.argmin(distances)\n",
    "                self.classifications[closest_centroid_idx].append(datapoint)\n",
    "            \n",
    "            prev_centroids = np.copy(self.centroids)\n",
    "            for i, classification in enumerate(self.classifications):\n",
    "                # Efficiently compute new centroids\n",
    "                if classification:  # Check if classification is not empty\n",
    "                    self.centroids[i] = np.mean(classification, axis=0)\n",
    "            \n",
    "            # Check for convergence\n",
    "            optimised_flag = True\n",
    "            for i in range(self.k):\n",
    "                diff = np.linalg.norm(prev_centroids[i] - self.centroids[i])\n",
    "                if diff >= self.tol:\n",
    "                    optimised_flag = False\n",
    "                    break\n",
    "            \n",
    "            if optimised_flag:\n",
    "                break\n",
    "\n",
    "    def elbow_method(self):\n",
    "        total_var = 0\n",
    "        for i, centroid in enumerate(self.centroids):\n",
    "            for datapoint in self.classifications[i]:\n",
    "                total_var += dtw.distance_fast(centroid, datapoint)\n",
    "        return total_var\n",
    "    \n",
    "    def display_clusters(self):\n",
    "        for i, cluster in enumerate(self.classifications, start = 1):\n",
    "            plt.figure(figsize=(3, 1.5))\n",
    "            for series in cluster:\n",
    "                plt.plot(series)\n",
    "\n",
    "        plt.title(f'Cluster {i} Time Series')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "23f4adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_KMeans = KMeansDTW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f61de2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[203 400 274]\n",
      "[[-0.9924995  -0.99150183 -0.98640069 -0.97765588 -0.97927818 -0.97677967\n",
      "  -0.98046672 -0.97646735 -0.97794217 -0.9796946  -0.97722211 -0.98251411\n",
      "  -0.98142968 -0.98086578 -0.98156849 -0.98000692 -0.97939097 -0.97811568\n",
      "  -0.97616372 -0.97378665 -0.97752575 -0.97228581 -0.97290176 -0.97326613\n",
      "  -0.97637192 -0.97501856 -0.96800884 -0.97102788 -0.96825175 -0.9687983\n",
      "  -0.96983067 -0.97022974 -0.97915673 -0.9791307  -0.97782072 -0.97848005]\n",
      " [ 1.57500343  1.58638555  1.67893476  1.68174559  1.72048994  1.69703165\n",
      "   1.69608603  1.69127985  1.67959409  1.6902041   1.68434821  1.68044428\n",
      "   1.65086983  1.65838273  1.63270353  1.66095065  1.68825214  1.65205836\n",
      "   1.62945893  1.6491174   1.63053468  1.76366742  1.72786403  1.67189033\n",
      "   1.68414     1.77134515  1.80802476  1.84202366  1.83946442  1.84806174\n",
      "   1.93428657  1.95412722  1.94246748  2.08698235  2.14286062  2.12751383]\n",
      " [-0.75553086 -0.75298897 -0.75094157 -0.73772893 -0.7401407  -0.73982838\n",
      "  -0.7408434  -0.74394052 -0.74629156 -0.74361086 -0.74683811 -0.75131462\n",
      "  -0.74982245 -0.75411677 -0.75389989 -0.74769697 -0.74540667 -0.75191322\n",
      "  -0.75374373 -0.75193057 -0.74706367 -0.74311636 -0.74162419 -0.74650844\n",
      "  -0.74807001 -0.74738466 -0.75485418 -0.75419485 -0.75243374 -0.75664131\n",
      "  -0.76694769 -0.7638072  -0.76653127 -0.77085162 -0.76820563 -0.76741616]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (234,) (234,36) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmy_KMeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtester\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_KMeans\u001b[38;5;241m.\u001b[39mclassifications)\n",
      "Cell \u001b[1;32mIn[106], line 42\u001b[0m, in \u001b[0;36mKMeansDTW.create_clusters\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classification \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifications:\n\u001b[0;32m     41\u001b[0m     new_centroid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(classification, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m     classification \u001b[38;5;241m=\u001b[39m classification[\u001b[43mclassification\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_centroid\u001b[49m]\n\u001b[0;32m     44\u001b[0m optimised_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk):\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (234,) (234,36) "
     ]
    }
   ],
   "source": [
    "my_KMeans.create_clusters(tester)\n",
    "print(my_KMeans.classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "86fdb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchDTW():\n",
    "    def __init__(self, data: np.ndarray):\n",
    "        self.data = data\n",
    "        self.linkages_matrix = None\n",
    "    \n",
    "    def calc_dist_matrix(self):\n",
    "        num_datapoints = self.data.shape[0]\n",
    "        self.distance_matrix = np.zeros((num_datapoints, num_datapoints))\n",
    "        for i in range(num_datapoints):\n",
    "            for j in range(i + 1, num_datapoints):\n",
    "                self.distance_matrix[i][j] = self.distance_matrix[j][i] = dtw.distance_fast(self.data[i], self.data[j])\n",
    "        \n",
    "    def cluster(self, method = 'ward'):\n",
    "        if self.linkages_matrix is None:\n",
    "            self.calc_dist_matrix()\n",
    "        self.linkages_matrix = linkage(squareform(self.distance_matrix), method = method)\n",
    "\n",
    "    def plot_dendrogram(self):\n",
    "        if self.linkages_matrix is None:\n",
    "            print('not clustered yet')\n",
    "        else:\n",
    "            plt.figure(figsize = (10, 7))\n",
    "            dendrogram(self.linkages_matrix)\n",
    "            plt.xlabel('Sample index')\n",
    "            plt.ylabel('Distance')\n",
    "            plt.show()\n",
    "\n",
    "    def display_clusters(self, max_clusters: int):\n",
    "        print(self.linkages_matrix.shape)\n",
    "        cluster_labels = fcluster(self.linkages_matrix, t = max_clusters, criterion = 'maxclust')\n",
    "        print(cluster_labels, type(cluster_labels))\n",
    "        for i in range(1,  len(np.unique(cluster_labels)) + 1):\n",
    "            idx = np.where(cluster_labels == i)\n",
    "            plt.plot(self.data[idx])\n",
    "            plt.title(f'Cluster {i} for hierarchical')\n",
    "            plt.show()\n",
    "        \n",
    "    def find_outliers_idx(self, max_clusters: int, cluster_nums : [int]):\n",
    "        # assumes that \n",
    "        idx = np.array([])\n",
    "        cluster_labels = fcluster(self.linkages_matrix, t = max_clusters, criterion = 'maxclust')\n",
    "        for i in cluster_nums:\n",
    "            idx = np.append(idx, np.where(cluster_labels == i))\n",
    "        return idx\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c703919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on visual inspection, cluster 6, 7 and 12 look to be outliers so i will cut them outj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b1ea75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indicators():\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def rate_of_change(self, period=14):\n",
    "        return self.data['close'].diff(period) / self.data['close'].shift(period)\n",
    "    \n",
    "    def compute_rsi(self, window=14):\n",
    "        delta = self.data['close'].diff()\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "        avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "        avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def exponential_moving_average(self, period=14):\n",
    "        return self.data['close'].ewm(span=period, adjust=False).mean()\n",
    "\n",
    "    def moving_average_convergence_divergence(self, slow=26, fast=12, signal=9):\n",
    "        ema_fast = self.exponential_moving_average(fast)\n",
    "        ema_slow = self.exponential_moving_average(slow)\n",
    "        macd = ema_fast - ema_slow\n",
    "        signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "        return macd, signal_line\n",
    "\n",
    "    def commodity_channel_index(self, period=14):\n",
    "        TP = (self.data['high'] + self.data['low'] + self.data['close']) / 3\n",
    "        CCI = (TP - TP.rolling(window=period).mean()) / (0.015 * TP.rolling(window=period).std())\n",
    "        return CCI\n",
    "\n",
    "    def bollinger_bands(self, period=14, num_std_dev=2):\n",
    "        sma = self.data['close'].rolling(window=period).mean()\n",
    "        std_dev = self.data['close'].rolling(window=period).std()\n",
    "        upper_band = sma + (std_dev * num_std_dev)\n",
    "        lower_band = sma - (std_dev * num_std_dev)\n",
    "        return upper_band, lower_band\n",
    "\n",
    "    def stochastic_oscillator(self, period=14):\n",
    "        low_min = self.data['low'].rolling(window=period).min()\n",
    "        high_max = self.data['high'].rolling(window=period).max()\n",
    "        stoch = ((self.data['close'] - low_min) / (high_max - low_min)) * 100\n",
    "        return stoch\n",
    "\n",
    "    def price_volume_volatility(self, period=14):\n",
    "        price_volatility = self.data['close'].rolling(window=period).std()\n",
    "        volume_volatility = self.data['Volume USD'].rolling(window=period).std()\n",
    "        return price_volatility, volume_volatility\n",
    "    \n",
    "    def label_data(self, thresh):\n",
    "        result = np.zeros_like(self.data)\n",
    "        changes = self.data.pct_change()\n",
    "        print(changes)\n",
    "        result[changes >= thresh] = 1\n",
    "        result[changes <= - thresh] = -1\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "3e3a4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(series, window: int, slide: int, train_proportion = 0.7):\n",
    "    split = []\n",
    "    series = zscore(series)\n",
    "    for i in range(0, int(len(series) * train_proportion) - window, slide):\n",
    "        split.append(list(series.iloc[i:i+window]))\n",
    "    return np.array(split)\n",
    "\n",
    "# Return array with 1 if price has gone up or -1 if price has gone down more than threshold\n",
    "def label_data(data, thresh):\n",
    "    result = np.zeros_like(data)\n",
    "    changes = data.pct_change()\n",
    "    print(changes)\n",
    "    result[changes >= thresh] = 1\n",
    "    result[changes <= - thresh] = -1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "12c58509",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'NoneType'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[338], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# X = indicators.data[['RSI', 'EMA', 'MACD', 'MACD_signal', 'CCI', 'Upper_BB', 'Lower_BB', 'Stochastic_Oscillator', 'Price_Volatility']]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Y = indicators.data['Label']\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m [indicators\u001b[38;5;241m.\u001b[39mcompute_rsi(), indicators\u001b[38;5;241m.\u001b[39mexponential_moving_average(), indicators\u001b[38;5;241m.\u001b[39mmoving_average_convergence_divergence()[\u001b[38;5;241m0\u001b[39m], indicators\u001b[38;5;241m.\u001b[39mmoving_average_convergence_divergence()[\u001b[38;5;241m1\u001b[39m], indicators\u001b[38;5;241m.\u001b[39mcommodity_channel_index(), indicators\u001b[38;5;241m.\u001b[39mbollinger_bands()[\u001b[38;5;241m0\u001b[39m], indicators\u001b[38;5;241m.\u001b[39mbollinger_bands()[\u001b[38;5;241m1\u001b[39m], indicators\u001b[38;5;241m.\u001b[39mstochastic_oscillator(), indicators\u001b[38;5;241m.\u001b[39mprice_volume_volatility()]\n\u001b[1;32m----> 6\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mindicators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, Y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, )\n\u001b[0;32m      8\u001b[0m tester \u001b[38;5;241m=\u001b[39m split_time_series(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m36\u001b[39m, \u001b[38;5;241m18\u001b[39m)\n",
      "Cell \u001b[1;32mIn[334], line 56\u001b[0m, in \u001b[0;36mIndicators.label_data\u001b[1;34m(self, thresh)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlabel_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, thresh):\n\u001b[0;32m     55\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m---> 56\u001b[0m     changes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpct_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(changes)\n\u001b[0;32m     58\u001b[0m     result[changes \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m thresh] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\generic.py:10959\u001b[0m, in \u001b[0;36mNDFrame.pct_change\u001b[1;34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[0m\n\u001b[0;32m  10957\u001b[0m shifted \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshift(periods\u001b[38;5;241m=\u001b[39mperiods, freq\u001b[38;5;241m=\u001b[39mfreq, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  10958\u001b[0m \u001b[38;5;66;03m# Unsupported left operand type for / (\"NDFrameT\")\u001b[39;00m\n\u001b[1;32m> 10959\u001b[0m rs \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshifted\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m  10960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m  10961\u001b[0m     \u001b[38;5;66;03m# Shift method is implemented differently when freq is not None\u001b[39;00m\n\u001b[0;32m  10962\u001b[0m     \u001b[38;5;66;03m# We want to restore the original index\u001b[39;00m\n\u001b[0;32m  10963\u001b[0m     rs \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mrs\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mduplicated()]\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruediv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\frame.py:7457\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7453\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m   7455\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_FRAME(\u001b[38;5;28mself\u001b[39m, other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 7457\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\frame.py:7496\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   7490\u001b[0m     \u001b[38;5;66;03m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[0;32m   7491\u001b[0m     \u001b[38;5;66;03m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[0;32m   7492\u001b[0m     \u001b[38;5;66;03m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[0;32m   7493\u001b[0m \n\u001b[0;32m   7494\u001b[0m     \u001b[38;5;66;03m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[0;32m   7495\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 7496\u001b[0m         bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperate_blockwise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7497\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;49;00m\n\u001b[0;32m   7498\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7499\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# \"ArrayManager\"\u001b[39;49;00m\n\u001b[0;32m   7500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;49;00m\n\u001b[0;32m   7501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7502\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# \"BlockManager\"\u001b[39;49;00m\n\u001b[0;32m   7503\u001b[0m \u001b[43m            \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7504\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(bm)\n\u001b[0;32m   7508\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, Series) \u001b[38;5;129;01mand\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   7509\u001b[0m     \u001b[38;5;66;03m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1545\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[1;34m(self, other, array_op)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moperate_blockwise\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: BlockManager, array_op) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BlockManager:\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;124;03m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperate_blockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\internals\\ops.py:63\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[1;34m(left, right, array_op)\u001b[0m\n\u001b[0;32m     61\u001b[0m res_blks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[38;5;129;01min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[1;32m---> 63\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43marray_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left_ea \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_ea \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     65\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:178\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\anaconda3\\envs\\quant-soc-env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:116\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 116\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('TrainData.csv', delimiter=',')\n",
    "my_Hierarch = HierarchDTW(train_df)\n",
    "my_Hierarch.cluster()\n",
    "my_Hierarch.find_outliers_idx(12, [6, 7, 12])\n",
    "\n",
    "indicators = Indicators(train_df)\n",
    "# X = indicators.data[['RSI', 'EMA', 'MACD', 'MACD_signal', 'CCI', 'Upper_BB', 'Lower_BB', 'Stochastic_Oscillator', 'Price_Volatility']]\n",
    "# Y = indicators.data['Label']\n",
    "X = [indicators.compute_rsi(), indicators.exponential_moving_average(), indicators.moving_average_convergence_divergence()[0], indicators.moving_average_convergence_divergence()[1], indicators.commodity_channel_index(), indicators.bollinger_bands()[0], indicators.bollinger_bands()[1], indicators.stochastic_oscillator(), indicators.price_volume_volatility()]\n",
    "Y = indicators.label_data(0.5)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, shuffle = None, )\n",
    "tester = split_time_series(train_df['close'], 36, 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0833be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
