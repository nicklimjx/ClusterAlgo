{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a4a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from dtaidistance import dtw\n",
    "import ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d065115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtest:\n",
    "    def __init__(self, csv :str, start :int, interval :int, port) -> None:\n",
    "        self.df = pd.read_csv(csv, delimiter=',')\n",
    "        self.start_idx = self.current_idx = self.df.index[self.df['unix'] == start][0]\n",
    "        self.interval = int(interval / 3600)\n",
    "        self.port = port\n",
    "        self.owned = 0\n",
    "\n",
    "    def get_close(self, datapoints :int):\n",
    "        return self.df.iloc[self.start_idx:self.start_idx + self.interval * datapoints:self.interval]['close']\n",
    "    \n",
    "    def get_price(self):\n",
    "        return self.df.iloc[self.current_idx]['open']\n",
    "\n",
    "    def buy(self, volume: float):\n",
    "            self.owned += volume\n",
    "            self.port -= volume * self.get_price()\n",
    "\n",
    "    def sell(self, volume: float):\n",
    "        if self.owned >= volume:\n",
    "            self.port += volume * self.get_price()\n",
    "            self.owned -= volume\n",
    "        else:\n",
    "            self.port = self.owned * self.get_price()\n",
    "            self.owned = 0\n",
    "\n",
    "    def simple_rsi(self, datapoints :int, lookback=24):\n",
    "        changes = self.get_close(datapoints).pct_change()\n",
    "        simple_rsis = [np.nan]*lookback\n",
    "\n",
    "        for window in changes.rolling(window=lookback):\n",
    "    \n",
    "            if len(window) != lookback: continue\n",
    "\n",
    "            positives = window[window>0].sum()\n",
    "            negatives = window[window<0].sum() * -1\n",
    "\n",
    "            simple_rsis.append(100 - 100/(1 + positives/negatives))\n",
    "\n",
    "        return pd.Series(index = self.get_close(datapoints).index, data=simple_rsis[:-1])\n",
    "    \n",
    "    def get_signals(self, datapoints, buy_thresh: int, sell_thresh: int):\n",
    "        rsi_data = self.simple_rsi(datapoints)\n",
    "        print(f'length of rsi_data is {len(rsi_data)}')\n",
    "        actions = []\n",
    "        for rsi in rsi_data:\n",
    "            if rsi == np.nan: actions.append(None)\n",
    "            \n",
    "            if rsi >= sell_thresh: actions.append('SELL')\n",
    "            elif rsi <= buy_thresh: actions.append('BUY')\n",
    "            else: actions.append(None)\n",
    "        print(f'length of actions is {len(actions)}')\n",
    "        return pd.Series(index=rsi_data.index, data=actions)\n",
    "\n",
    "    def calc_pnl(self):\n",
    "        return self.port + self.owned * self.get_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8c1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algo():\n",
    "    ETHUSD = Backtest('BacktestData.csv', 1670396400, 3600*4, 10000)\n",
    "    signals = ETHUSD.get_signals(2000, 35, 65)\n",
    "    k = []\n",
    "    for signal in signals:\n",
    "        if signal == 'BUY' :\n",
    "            ETHUSD.buy(ETHUSD.port/ETHUSD.get_price())\n",
    "        elif signal == 'SELL':\n",
    "            ETHUSD.sell(ETHUSD.owned)\n",
    "        else:\n",
    "            pass\n",
    "        ETHUSD.current_idx += ETHUSD.interval\n",
    "        k.append(ETHUSD.calc_pnl())\n",
    "    print(max(k))\n",
    "    print(ETHUSD.calc_pnl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00b917db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_algo\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_algo' is not defined"
     ]
    }
   ],
   "source": [
    "run_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32404baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data labeling\n",
    "# write + implement dtw\n",
    "# implement kmeans clustering (+ heirarchical clustering as a side bonus?)\n",
    "# cut out outliers from the dataset\n",
    "# create the ml model using indicators (see paper)\n",
    "# train the model (80/20 train test split)\n",
    "# signal generation + final implementation + paper live test?\n",
    "# + finding optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9be918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansDTW():\n",
    "    def __init__(self, k: int = 8, max_iter: int = 3000, tol: float = 0.001):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    def create_clusters(self, data: np.ndarray):\n",
    "        # Initialize centroids randomly\n",
    "        rand_idx = np.random.choice(data.shape[0], self.k, replace=False)\n",
    "        self.centroids = data[rand_idx]\n",
    "        \n",
    "        for _ in tqdm(range(self.max_iter)):\n",
    "            self.classifications = [[] for _ in range(self.k)]\n",
    "            \n",
    "            # Precompute distances between each datapoint and each centroid\n",
    "            # This step is assumed to be the optimized part; depending on the fastdtw implementation details\n",
    "            # You might need to manually loop through data and centroids if fastdtw cannot be vectorized directly\n",
    "            for i, datapoint in enumerate(data):\n",
    "                distances = np.array([dtw.distance_fast(centroid, datapoint) for centroid in self.centroids])\n",
    "                closest_centroid_idx = np.argmin(distances)\n",
    "                self.classifications[closest_centroid_idx].append(datapoint)\n",
    "            \n",
    "            prev_centroids = np.copy(self.centroids)\n",
    "            for i, classification in enumerate(self.classifications):\n",
    "                # Efficiently compute new centroids\n",
    "                if classification:  # Check if classification is not empty\n",
    "                    self.centroids[i] = np.mean(classification, axis=0)\n",
    "            \n",
    "            # Check for convergence\n",
    "            optimised_flag = True\n",
    "            for i in range(self.k):\n",
    "                diff = np.linalg.norm(prev_centroids[i] - self.centroids[i])\n",
    "                if diff >= self.tol:\n",
    "                    optimised_flag = False\n",
    "                    break\n",
    "            \n",
    "            if optimised_flag:\n",
    "                break\n",
    "\n",
    "    def elbow_method(self):\n",
    "        total_var = 0\n",
    "        for i, centroid in enumerate(self.centroids):\n",
    "            for datapoint in self.classifications[i]:\n",
    "                total_var += dtw.distance_fast(centroid, datapoint)\n",
    "        return total_var\n",
    "    \n",
    "    def display_clusters(self):\n",
    "        for i, cluster in enumerate(self.classifications, start = 1):\n",
    "            plt.figure(figsize=(3, 1.5))\n",
    "            for series in cluster:\n",
    "                plt.plot(series)\n",
    "\n",
    "        plt.title(f'Cluster {i} Time Series')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f4adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_KMeans = KMeansDTW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f61de2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[203 400 274]\n",
      "[[-0.9924995  -0.99150183 -0.98640069 -0.97765588 -0.97927818 -0.97677967\n",
      "  -0.98046672 -0.97646735 -0.97794217 -0.9796946  -0.97722211 -0.98251411\n",
      "  -0.98142968 -0.98086578 -0.98156849 -0.98000692 -0.97939097 -0.97811568\n",
      "  -0.97616372 -0.97378665 -0.97752575 -0.97228581 -0.97290176 -0.97326613\n",
      "  -0.97637192 -0.97501856 -0.96800884 -0.97102788 -0.96825175 -0.9687983\n",
      "  -0.96983067 -0.97022974 -0.97915673 -0.9791307  -0.97782072 -0.97848005]\n",
      " [ 1.57500343  1.58638555  1.67893476  1.68174559  1.72048994  1.69703165\n",
      "   1.69608603  1.69127985  1.67959409  1.6902041   1.68434821  1.68044428\n",
      "   1.65086983  1.65838273  1.63270353  1.66095065  1.68825214  1.65205836\n",
      "   1.62945893  1.6491174   1.63053468  1.76366742  1.72786403  1.67189033\n",
      "   1.68414     1.77134515  1.80802476  1.84202366  1.83946442  1.84806174\n",
      "   1.93428657  1.95412722  1.94246748  2.08698235  2.14286062  2.12751383]\n",
      " [-0.75553086 -0.75298897 -0.75094157 -0.73772893 -0.7401407  -0.73982838\n",
      "  -0.7408434  -0.74394052 -0.74629156 -0.74361086 -0.74683811 -0.75131462\n",
      "  -0.74982245 -0.75411677 -0.75389989 -0.74769697 -0.74540667 -0.75191322\n",
      "  -0.75374373 -0.75193057 -0.74706367 -0.74311636 -0.74162419 -0.74650844\n",
      "  -0.74807001 -0.74738466 -0.75485418 -0.75419485 -0.75243374 -0.75664131\n",
      "  -0.76694769 -0.7638072  -0.76653127 -0.77085162 -0.76820563 -0.76741616]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (234,) (234,36) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmy_KMeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtester\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_KMeans\u001b[38;5;241m.\u001b[39mclassifications)\n",
      "Cell \u001b[1;32mIn[106], line 42\u001b[0m, in \u001b[0;36mKMeansDTW.create_clusters\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classification \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifications:\n\u001b[0;32m     41\u001b[0m     new_centroid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(classification, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m     classification \u001b[38;5;241m=\u001b[39m classification[\u001b[43mclassification\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_centroid\u001b[49m]\n\u001b[0;32m     44\u001b[0m optimised_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk):\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (234,) (234,36) "
     ]
    }
   ],
   "source": [
    "my_KMeans.create_clusters(tester)\n",
    "print(my_KMeans.classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fdb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchDTW():\n",
    "    # inits a df but operates on [subseries]\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df= df\n",
    "        self.linkages_matrix = None\n",
    "    \n",
    "    def split_time_series(self, window: int, slide: int):\n",
    "        self.data = []\n",
    "        series = zscore(self.df['close'])\n",
    "        for i in range(0, len(series) - window, slide):\n",
    "            self.data.append(list(series.iloc[i:i+window]))\n",
    "        self.data = np.array(self.data)\n",
    "\n",
    "    def calc_dist_matrix(self):\n",
    "        num_datapoints = self.data.shape[0]\n",
    "        self.distance_matrix = np.zeros((num_datapoints, num_datapoints))\n",
    "        for i in range(num_datapoints):\n",
    "            for j in range(i + 1, num_datapoints):\n",
    "                self.distance_matrix[i][j] = self.distance_matrix[j][i] = dtw.distance_fast(self.data[i], self.data[j])\n",
    "        \n",
    "    def cluster(self, method = 'ward'):\n",
    "        if self.linkages_matrix is None:\n",
    "            self.split_time_series(window = 36, slide = 18)\n",
    "            print(type(self.data), type(self.data[0]))\n",
    "            print(self.data)\n",
    "            self.calc_dist_matrix()\n",
    "        self.linkages_matrix = linkage(squareform(self.distance_matrix), method = method)\n",
    "\n",
    "    def plot_dendrogram(self):\n",
    "        if self.linkages_matrix is None:\n",
    "            print('not clustered yet')\n",
    "        else:\n",
    "            plt.figure(figsize = (10, 7))\n",
    "            dendrogram(self.linkages_matrix)\n",
    "            plt.xlabel('Sample index')\n",
    "            plt.ylabel('Distance')\n",
    "            plt.show()\n",
    "\n",
    "    def get_clusters(self, max_clusters, criterion = 'maxclust'):\n",
    "        return fcluster(self.linkages_matrix, t = max_clusters, criterion = criterion)\n",
    "        \n",
    "\n",
    "    def display_clusters(self, max_clusters: int):\n",
    "        print(self.linkages_matrix.shape)\n",
    "        cluster_labels = self.get_clusters(max_clusters)\n",
    "        # print(cluster_labels, type(cluster_labels))\n",
    "        for i in range(1,  len(np.unique(cluster_labels)) + 1):\n",
    "            idx = np.where(cluster_labels == i)\n",
    "            plt.plot(self.data[idx])\n",
    "            plt.title(f'Cluster {i} for hierarchical')\n",
    "            plt.show()\n",
    "        \n",
    "    def find_outliers_idx(self, max_clusters: int, cluster_nums : [int]):\n",
    "        # assumes that \n",
    "        idx = np.array([])\n",
    "        cluster_labels = fcluster(self.linkages_matrix, t = max_clusters, criterion = 'maxclust')\n",
    "        for i in cluster_nums:\n",
    "            idx = np.append(idx, np.where(cluster_labels == i))\n",
    "        # print(idx, type(idx), type(idx[0]))\n",
    "        return idx.astype(int)\n",
    "    \n",
    "    def return_cleaned_data(self, max_clusters, cluster_nums):\n",
    "        outliers = self.find_outliers_idx(max_clusters = max_clusters, cluster_nums = cluster_nums)\n",
    "        return np.delete(self.data, outliers, axis = 0)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c703919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on visual inspection, cluster 6, 7 and 12 look to be outliers so i will cut them outj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ea75df",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (475405741.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.df['ROC'] = self.df['close'].diff(period) / self.df['close'].shift(period)-\u001b[0m\n\u001b[1;37m                                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Indicators():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def rate_of_change(self, period=14):\n",
    "        self.df['ROC'] = self.df['close'].diff(period) / self.df['close'].shift(period)-\n",
    "    \n",
    "    def compute_rsi(self, window=14):\n",
    "        delta = self.df['close'].diff()\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "        avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "        avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        self.df['RSI'] = rsi\n",
    "\n",
    "    def exponential_moving_average(self, period=14):\n",
    "        self.df['EMA'] = self.df['close'].ewm(span=period, adjust=False).mean()\n",
    "\n",
    "    def moving_average_convergence_divergence(self, slow=26, fast=12, signal=9):\n",
    "        ema_fast = self.exponential_moving_average(fast)\n",
    "        ema_slow = self.exponential_moving_average(slow)\n",
    "        macd = ema_fast - ema_slow\n",
    "        signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "        df['MACD'] = macd.macd()\n",
    "        df['MACD_signal'] = macd.signal_line\n",
    "        df['MACD_diff'] = macd.macd_diff()\n",
    "\n",
    "    def commodity_channel_index(self, period=14):\n",
    "        TP = (self.df['high'] + self.data['low'] + self.df['close']) / 3\n",
    "        CCI = (TP - TP.rolling(window=period).mean()) / (0.015 * TP.rolling(window=period).std())\n",
    "        return CCI\n",
    "\n",
    "    def bollinger_bands(self, period=14, num_std_dev=2):\n",
    "        sma = self.df['close'].rolling(window=period).mean()\n",
    "        std_dev = self.df['close'].rolling(window=period).std()\n",
    "        upper_band = sma + (std_dev * num_std_dev)\n",
    "        lower_band = sma - (std_dev * num_std_dev)\n",
    "        return upper_band, lower_band\n",
    "\n",
    "    def stochastic_oscillator(self, period=14):\n",
    "        low_min = self.df['low'].rolling(window=period).min()\n",
    "        high_max = self.df['high'].rolling(window=period).max()\n",
    "        stoch = ((self.df['close'] - low_min) / (high_max - low_min)) * 100\n",
    "        return stoch\n",
    "\n",
    "    def price_volume_volatility(self, period=14):\n",
    "        price_volatility = self.df['close'].rolling(window=period).std()\n",
    "        volume_volatility = self.df['Volume USD'].rolling(window=period).std()\n",
    "        return price_volatility, volume_volatility\n",
    "    \n",
    "    def slice_featureset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0a500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indicators():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def calculate_roc(self):\n",
    "        self.df['ROC'] = ta.momentum.ROCIndicator(close=self.df['close']).roc()\n",
    "\n",
    "    def calculate_rsi(self):\n",
    "        self.df['RSI'] = ta.momentum.RSIIndicator(close=self.df['close']).rsi()\n",
    "\n",
    "    def calculate_ema(self):\n",
    "        self.df['EMA'] = ta.trend.EMAIndicator(close=self.df['close']).ema_indicator()\n",
    "\n",
    "    def calculate_macd(self):\n",
    "        macd = ta.trend.MACD(close=self.df['close'])\n",
    "        self.df['MACD'] = macd.macd()\n",
    "        self.df['MACD_signal'] = macd.macd_signal()\n",
    "        self.df['MACD_diff'] = macd.macd_diff()\n",
    "\n",
    "    def calculate_cci(self):\n",
    "        self.df['CCI'] = ta.trend.CCIIndicator(high=self.df['high'], low=self.df['low'], close=self.df['close']).cci()\n",
    "\n",
    "    def calculate_bollinger(self):\n",
    "        bollinger = ta.volatility.BollingerBands(close=self.df['close'])\n",
    "        self.df['Bollinger_Mavg'] = bollinger.bollinger_mavg()\n",
    "        self.df['Bollinger_hband'] = bollinger.bollinger_hband()\n",
    "        self.df['Bollinger_lband'] = bollinger.bollinger_lband()\n",
    "\n",
    "    def calculate_stochastic(self):\n",
    "        stoch = ta.momentum.StochasticOscillator(high=self.df['high'], low=self.df['low'], close=self.df['close'])\n",
    "        self.df['Stoch_%K'] = stoch.stoch()\n",
    "        self.df['Stoch_%D'] = stoch.stoch_signal()\n",
    "\n",
    "    def get_featureset(self):\n",
    "        \n",
    "        self.calculate_roc()\n",
    "        self.calculate_rsi()\n",
    "        self.calculate_ema()\n",
    "        self.calculate_macd()\n",
    "        self.calculate_cci()\n",
    "        self.calculate_bollinger()\n",
    "        self.calculate_stochastic()\n",
    "\n",
    "        return self.df[['ROC', 'RSI', 'EMA', 'MACD', 'MACD_signal', 'MACD_diff', 'CCI', 'Bollinger_Mavg', 'Bollinger_hband', 'Bollinger_lband', 'Stoch_%K', 'Stoch_%D']]\n",
    "    \n",
    "    def slice_idx(self, window, slide):\n",
    "        slice_idx = []\n",
    "        series = zscore(self.df['close'])\n",
    "        for i in range(0, len(series) - window, slide):\n",
    "            slice_idx.append(range(i, i + window))\n",
    "        self.data = np.array(slice_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3e3a4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(series, window: int, slide: int, train_proportion = 0.7):\n",
    "    split = []\n",
    "    series = zscore(series)\n",
    "    for i in range(0, int(len(series) * train_proportion) - window, slide):\n",
    "        split.append(list(series.iloc[i:i+window]))\n",
    "    return np.array(split)\n",
    "\n",
    "# Return array with 1 if price has gone up or -1 if price has gone down more than threshold\n",
    "def label_data(data: np.ndarray, thresh):\n",
    "    result = np.zeros(data.shape[0])\n",
    "    closes = [subseries[-1] for subseries in data]\n",
    "    changes = [(closes[i + 1] - closes[i]) / closes[i] for i in range(len(closes) - 1)]\n",
    "    print(changes)\n",
    "    result[changes >= thresh] = 1\n",
    "    result[changes <= - thresh] = -1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "baab81a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[[-0.48572582 -0.48521397 -0.50406562 ... -0.49426242 -0.50312868\n",
      "  -0.50522813]\n",
      " [-0.54212462 -0.52957131 -0.53865446 ... -0.61854624 -0.616976\n",
      "  -0.60966263]\n",
      " [-0.49976262 -0.50814306 -0.51515279 ... -0.59851474 -0.61412179\n",
      "  -0.61466834]\n",
      " ...\n",
      " [ 0.93990318  0.96211222  0.9347847  ...  0.82694943  0.80161726\n",
      "   0.77376921]\n",
      " [ 0.83649238  0.82347927  0.81098669 ...  0.99204236  1.08990091\n",
      "   1.11826947]\n",
      " [ 0.79910139  0.81081319  0.84239165 ...  1.10013788  1.11427879\n",
      "   1.09996437]]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('TrainData.csv', delimiter=',')\n",
    "my_Hierarch = HierarchDTW(train_df)\n",
    "my_Hierarch.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "12c58509",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Indicators' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m indicators\u001b[38;5;241m.\u001b[39mget_featureset()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Y = indicators.label()\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mindicators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRSI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACD_signal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCCI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_BB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_BB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStochastic_Oscillator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice_Volatility\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      7\u001b[0m Y \u001b[38;5;241m=\u001b[39m indicators\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, Y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Indicators' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "indicators = Indicators(train_df)\n",
    "indicators.run_all()\n",
    "X = indicators.get_featureset()\n",
    "# Y = indicators.label()\n",
    "\n",
    "X = indicators.data[['RSI', 'EMA', 'MACD', 'MACD_signal', 'CCI', 'Upper_BB', 'Lower_BB', 'Stochastic_Oscillator', 'Price_Volatility']]\n",
    "Y = indicators.data['Label']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, shuffle = None)\n",
    "# tester = split_time_series(train_df['close'], 36, 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0833be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[0, 1], [2, 3], [4, 5]])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "34f7e5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. ])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1, 2])\n",
    "v * 0.5 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
