{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a4a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from dtaidistance import dtw\n",
    "import ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d065115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtest:\n",
    "    def __init__(self, csv :str, start :int, interval :int, port) -> None:\n",
    "        self.df = pd.read_csv(csv, delimiter=',')\n",
    "        self.start_idx = self.current_idx = self.df.index[self.df['unix'] == start][0]\n",
    "        self.interval = int(interval / 3600)\n",
    "        self.port = port\n",
    "        self.owned = 0\n",
    "\n",
    "    def get_close(self, datapoints :int):\n",
    "        return self.df.iloc[self.start_idx:self.start_idx + self.interval * datapoints:self.interval]['close']\n",
    "    \n",
    "    def get_price(self):\n",
    "        return self.df.iloc[self.current_idx]['open']\n",
    "\n",
    "    def buy(self, volume: float):\n",
    "            self.owned += volume\n",
    "            self.port -= volume * self.get_price()\n",
    "\n",
    "    def sell(self, volume: float):\n",
    "        if self.owned >= volume:\n",
    "            self.port += volume * self.get_price()\n",
    "            self.owned -= volume\n",
    "        else:\n",
    "            self.port = self.owned * self.get_price()\n",
    "            self.owned = 0\n",
    "\n",
    "    def simple_rsi(self, datapoints :int, lookback=24):\n",
    "        changes = self.get_close(datapoints).pct_change()\n",
    "        simple_rsis = [np.nan]*lookback\n",
    "\n",
    "        for window in changes.rolling(window=lookback):\n",
    "    \n",
    "            if len(window) != lookback: continue\n",
    "\n",
    "            positives = window[window>0].sum()\n",
    "            negatives = window[window<0].sum() * -1\n",
    "\n",
    "            simple_rsis.append(100 - 100/(1 + positives/negatives))\n",
    "\n",
    "        return pd.Series(index = self.get_close(datapoints).index, data=simple_rsis[:-1])\n",
    "    \n",
    "    def get_signals(self, datapoints, buy_thresh: int, sell_thresh: int):\n",
    "        rsi_data = self.simple_rsi(datapoints)\n",
    "        print(f'length of rsi_data is {len(rsi_data)}')\n",
    "        actions = []\n",
    "        for rsi in rsi_data:\n",
    "            if rsi == np.nan: actions.append(None)\n",
    "            \n",
    "            if rsi >= sell_thresh: actions.append('SELL')\n",
    "            elif rsi <= buy_thresh: actions.append('BUY')\n",
    "            else: actions.append(None)\n",
    "        print(f'length of actions is {len(actions)}')\n",
    "        return pd.Series(index=rsi_data.index, data=actions)\n",
    "\n",
    "    def calc_pnl(self):\n",
    "        return self.port + self.owned * self.get_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8c1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algo():\n",
    "    ETHUSD = Backtest('BacktestData.csv', 1670396400, 3600*4, 10000)\n",
    "    signals = ETHUSD.get_signals(2000, 35, 65)\n",
    "    k = []\n",
    "    for signal in signals:\n",
    "        if signal == 'BUY' :\n",
    "            ETHUSD.buy(ETHUSD.port/ETHUSD.get_price())\n",
    "        elif signal == 'SELL':\n",
    "            ETHUSD.sell(ETHUSD.owned)\n",
    "        else:\n",
    "            pass\n",
    "        ETHUSD.current_idx += ETHUSD.interval\n",
    "        k.append(ETHUSD.calc_pnl())\n",
    "    print(max(k))\n",
    "    print(ETHUSD.calc_pnl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00b917db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_algo\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_algo' is not defined"
     ]
    }
   ],
   "source": [
    "run_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32404baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data labeling\n",
    "# write + implement dtw\n",
    "# implement kmeans clustering (+ heirarchical clustering as a side bonus?)\n",
    "# cut out outliers from the dataset\n",
    "# create the ml model using indicators (see paper)\n",
    "# train the model (80/20 train test split)\n",
    "# signal generation + final implementation + paper live test?\n",
    "# + finding optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9be918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansDTW():\n",
    "    def __init__(self, k: int = 8, max_iter: int = 3000, tol: float = 0.001):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    def create_clusters(self, data: np.ndarray):\n",
    "        # Initialize centroids randomly\n",
    "        rand_idx = np.random.choice(data.shape[0], self.k, replace=False)\n",
    "        self.centroids = data[rand_idx]\n",
    "        \n",
    "        for _ in tqdm(range(self.max_iter)):\n",
    "            self.classifications = [[] for _ in range(self.k)]\n",
    "            \n",
    "            # Precompute distances between each datapoint and each centroid\n",
    "            # This step is assumed to be the optimized part; depending on the fastdtw implementation details\n",
    "            # You might need to manually loop through data and centroids if fastdtw cannot be vectorized directly\n",
    "            for i, datapoint in enumerate(data):\n",
    "                distances = np.array([dtw.distance_fast(centroid, datapoint) for centroid in self.centroids])\n",
    "                closest_centroid_idx = np.argmin(distances)\n",
    "                self.classifications[closest_centroid_idx].append(datapoint)\n",
    "            \n",
    "            prev_centroids = np.copy(self.centroids)\n",
    "            for i, classification in enumerate(self.classifications):\n",
    "                # Efficiently compute new centroids\n",
    "                if classification:  # Check if classification is not empty\n",
    "                    self.centroids[i] = np.mean(classification, axis=0)\n",
    "            \n",
    "            # Check for convergence\n",
    "            optimised_flag = True\n",
    "            for i in range(self.k):\n",
    "                diff = np.linalg.norm(prev_centroids[i] - self.centroids[i])\n",
    "                if diff >= self.tol:\n",
    "                    optimised_flag = False\n",
    "                    break\n",
    "            \n",
    "            if optimised_flag:\n",
    "                break\n",
    "\n",
    "    def elbow_method(self):\n",
    "        total_var = 0\n",
    "        for i, centroid in enumerate(self.centroids):\n",
    "            for datapoint in self.classifications[i]:\n",
    "                total_var += dtw.distance_fast(centroid, datapoint)\n",
    "        return total_var\n",
    "    \n",
    "    def display_clusters(self):\n",
    "        for i, cluster in enumerate(self.classifications, start = 1):\n",
    "            plt.figure(figsize=(3, 1.5))\n",
    "            for series in cluster:\n",
    "                plt.plot(series)\n",
    "\n",
    "        plt.title(f'Cluster {i} Time Series')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f4adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_KMeans = KMeansDTW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f61de2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[203 400 274]\n",
      "[[-0.9924995  -0.99150183 -0.98640069 -0.97765588 -0.97927818 -0.97677967\n",
      "  -0.98046672 -0.97646735 -0.97794217 -0.9796946  -0.97722211 -0.98251411\n",
      "  -0.98142968 -0.98086578 -0.98156849 -0.98000692 -0.97939097 -0.97811568\n",
      "  -0.97616372 -0.97378665 -0.97752575 -0.97228581 -0.97290176 -0.97326613\n",
      "  -0.97637192 -0.97501856 -0.96800884 -0.97102788 -0.96825175 -0.9687983\n",
      "  -0.96983067 -0.97022974 -0.97915673 -0.9791307  -0.97782072 -0.97848005]\n",
      " [ 1.57500343  1.58638555  1.67893476  1.68174559  1.72048994  1.69703165\n",
      "   1.69608603  1.69127985  1.67959409  1.6902041   1.68434821  1.68044428\n",
      "   1.65086983  1.65838273  1.63270353  1.66095065  1.68825214  1.65205836\n",
      "   1.62945893  1.6491174   1.63053468  1.76366742  1.72786403  1.67189033\n",
      "   1.68414     1.77134515  1.80802476  1.84202366  1.83946442  1.84806174\n",
      "   1.93428657  1.95412722  1.94246748  2.08698235  2.14286062  2.12751383]\n",
      " [-0.75553086 -0.75298897 -0.75094157 -0.73772893 -0.7401407  -0.73982838\n",
      "  -0.7408434  -0.74394052 -0.74629156 -0.74361086 -0.74683811 -0.75131462\n",
      "  -0.74982245 -0.75411677 -0.75389989 -0.74769697 -0.74540667 -0.75191322\n",
      "  -0.75374373 -0.75193057 -0.74706367 -0.74311636 -0.74162419 -0.74650844\n",
      "  -0.74807001 -0.74738466 -0.75485418 -0.75419485 -0.75243374 -0.75664131\n",
      "  -0.76694769 -0.7638072  -0.76653127 -0.77085162 -0.76820563 -0.76741616]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (234,) (234,36) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmy_KMeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtester\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_KMeans\u001b[38;5;241m.\u001b[39mclassifications)\n",
      "Cell \u001b[1;32mIn[106], line 42\u001b[0m, in \u001b[0;36mKMeansDTW.create_clusters\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classification \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifications:\n\u001b[0;32m     41\u001b[0m     new_centroid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(classification, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m     classification \u001b[38;5;241m=\u001b[39m classification[\u001b[43mclassification\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_centroid\u001b[49m]\n\u001b[0;32m     44\u001b[0m optimised_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk):\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (234,) (234,36) "
     ]
    }
   ],
   "source": [
    "my_KMeans.create_clusters(tester)\n",
    "print(my_KMeans.classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86fdb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchDTW():\n",
    "    # inits a df but operates on [subseries]\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df= df\n",
    "        self.linkages_matrix = None\n",
    "    \n",
    "    def split_time_series(self, window: int, slide: int):\n",
    "        self.data = []\n",
    "        series = zscore(self.df['close'])\n",
    "        for i in range(0, len(series) - window, slide):\n",
    "            self.data.append(list(series.iloc[i:i+window]))\n",
    "        self.data = np.array(self.data)\n",
    "\n",
    "    def calc_dist_matrix(self):\n",
    "        num_datapoints = self.data.shape[0]\n",
    "        self.distance_matrix = np.zeros((num_datapoints, num_datapoints))\n",
    "        for i in range(num_datapoints):\n",
    "            for j in range(i + 1, num_datapoints):\n",
    "                self.distance_matrix[i][j] = self.distance_matrix[j][i] = dtw.distance_fast(self.data[i], self.data[j])\n",
    "        \n",
    "    def cluster(self, method = 'ward'):\n",
    "        if self.linkages_matrix is None:\n",
    "            self.split_time_series(window = 36, slide = 18)\n",
    "            print(type(self.data), type(self.data[0]))\n",
    "            self.calc_dist_matrix()\n",
    "        self.linkages_matrix = linkage(squareform(self.distance_matrix), method = method)\n",
    "\n",
    "    def plot_dendrogram(self):\n",
    "        if self.linkages_matrix is None:\n",
    "            print('not clustered yet')\n",
    "        else:\n",
    "            plt.figure(figsize = (10, 7))\n",
    "            dendrogram(self.linkages_matrix)\n",
    "            plt.xlabel('Sample index')\n",
    "            plt.ylabel('Distance')\n",
    "            plt.show()\n",
    "\n",
    "    def get_clusters(self, max_clusters, criterion = 'maxclust'):\n",
    "        return fcluster(self.linkages_matrix, t = max_clusters, criterion = criterion)\n",
    "        \n",
    "\n",
    "    def display_clusters(self, max_clusters: int):\n",
    "        print(self.linkages_matrix.shape)\n",
    "        cluster_labels = self.get_clusters(max_clusters)\n",
    "        # print(cluster_labels, type(cluster_labels))\n",
    "        for i in range(1,  len(np.unique(cluster_labels)) + 1):\n",
    "            idx = np.where(cluster_labels == i)\n",
    "            plt.plot(self.data[idx])\n",
    "            plt.title(f'Cluster {i} for hierarchical')\n",
    "            plt.show()\n",
    "        \n",
    "    def find_outliers_idx(self, max_clusters: int, cluster_nums : [int]):\n",
    "        # assumes that \n",
    "        idx = np.array([])\n",
    "        cluster_labels = fcluster(self.linkages_matrix, t = max_clusters, criterion = 'maxclust')\n",
    "        for i in cluster_nums:\n",
    "            idx = np.append(idx, np.where(cluster_labels == i))\n",
    "        # print(idx, type(idx), type(idx[0]))\n",
    "        return idx.astype(int)\n",
    "    \n",
    "    def return_cleaned_data(self, max_clusters, cluster_nums):\n",
    "        outliers = self.find_outliers_idx(max_clusters = max_clusters, cluster_nums = cluster_nums)\n",
    "        return np.delete(self.data, outliers, axis = 0)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c703919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on visual inspection, cluster 6, 7 and 12 look to be outliers so i will cut them outj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0a500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indicators():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def calculate_roc(self, subseries):\n",
    "        roc_indicator = ta.momentum.ROCIndicator(close=subseries['close'], window = len(subseries) - 1).roc()\n",
    "        return roc_indicator.iloc[-1]\n",
    "\n",
    "    def calculate_rsi(self, subseries):\n",
    "        rsi_indicator = ta.momentum.RSIIndicator(close=subseries['close'], window = len(subseries)).rsi()\n",
    "        return rsi_indicator.iloc[-1]\n",
    "\n",
    "    def calculate_ema(self, subseries):\n",
    "        ema_indicator = ta.trend.EMAIndicator(close=subseries['close'], window = len(subseries)).ema_indicator()\n",
    "        return ema_indicator.iloc[-1]\n",
    "\n",
    "    def calculate_macd(self, subseries):\n",
    "        macd = ta.trend.MACD(close=subseries['close'], window_slow = 26, window_fast = 12, window_sign = 9)\n",
    "        macd_indicator = macd.macd()\n",
    "        macd_signal = macd.macd_signal()\n",
    "        macd_diff = macd.macd_diff()\n",
    "        return macd_indicator.iloc[-1], macd_signal.iloc[-1], macd_diff.iloc[-1]\n",
    "\n",
    "    def calculate_cci(self, subseries):\n",
    "        cci_indicator = ta.trend.CCIIndicator(high=subseries['high'], low=subseries['low'], close=subseries['close'], window = len(subseries)).cci()\n",
    "        return cci_indicator.iloc[-1]\n",
    "\n",
    "    def calculate_bollinger(self, subseries):\n",
    "        bollinger = ta.volatility.BollingerBands(close=subseries['close'], window = len(subseries))\n",
    "        bollinger_mavg = bollinger.bollinger_mavg()\n",
    "        bollinger_hband = bollinger.bollinger_hband()\n",
    "        bollinger_lband = bollinger.bollinger_lband()\n",
    "        return bollinger_mavg.iloc[-1], bollinger_hband.iloc[-1], bollinger_lband.iloc[-1]\n",
    "\n",
    "    def calculate_stochastic(self, subseries):\n",
    "        stoch = ta.momentum.StochasticOscillator(high=subseries['high'], low=subseries['low'], close=subseries['close'])\n",
    "        stoch_stoch = stoch.stoch()\n",
    "        stoch_signal = stoch.stoch_signal()\n",
    "        return stoch_stoch.iloc[-1], stoch_signal.iloc[-1]\n",
    "\n",
    "    def get_featureset(self, window):\n",
    "        featureset = []\n",
    "        for i in range(0, len(self.df['close']) - window, int(window/2)):\n",
    "            subseries = self.df.iloc[i:i + window]\n",
    "            features = {\n",
    "                'ROC': self.calculate_roc(subseries),\n",
    "                'RSI': self.calculate_rsi(subseries),\n",
    "                'EMA': self.calculate_ema(subseries),\n",
    "                # For MACD, signal, and diff, handle multiple return values\n",
    "                'MACD': self.calculate_macd(subseries)[0],\n",
    "                'MACD_signal': self.calculate_macd(subseries)[1],\n",
    "                'MACD_diff': self.calculate_macd(subseries)[2],\n",
    "                'CCI': self.calculate_cci(subseries),\n",
    "                # Bollinger Bands\n",
    "                'Bollinger_Mavg': self.calculate_bollinger(subseries)[0],\n",
    "                'Bollinger_hband': self.calculate_bollinger(subseries)[1],\n",
    "                'Bollinger_lband': self.calculate_bollinger(subseries)[2],\n",
    "                'Stoch_%K': self.calculate_stochastic(subseries)[0],\n",
    "                'Stoch_%D': self.calculate_stochastic(subseries)[1],\n",
    "            }\n",
    "            featureset.append(features)\n",
    "        \n",
    "        return pd.DataFrame(featureset)\n",
    "    \n",
    "    # def slice_idx(self, window, slide):\n",
    "    #     slice_idx = []\n",
    "    #     series = zscore(self.df['close'])\n",
    "    #     for i in range(0, len(series) - window, slide):\n",
    "    #         slice_idx.append(range(i, i + window))\n",
    "    #     self.data = np.array(slice_idx)\n",
    "    \n",
    "    def return_labels(self, window, thresh):\n",
    "        labels = []\n",
    "        for i in range(0, len(self.df['close']) - window, int(window/2)):\n",
    "            current_price = self.df['close'].iloc[i]\n",
    "            future_price = self.df['close'].iloc[i + window]\n",
    "            pct_change = (future_price - current_price) / current_price * 100\n",
    "            # Determine label based on threshold\n",
    "            if pct_change >= thresh: labels.append(1)\n",
    "            elif pct_change <= -thresh: labels.append(-1)\n",
    "            else: labels.append(0)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baab81a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('TrainData.csv', delimiter=',')\n",
    "my_Hierarch = HierarchDTW(train_df)\n",
    "my_Hierarch.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12c58509",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 36\n",
    "slide = 18\n",
    "indicators = Indicators(train_df)\n",
    "X_uncleaned = indicators.get_featureset(window)\n",
    "Y_uncleaned = indicators.return_labels(thresh = 0.015, window = window)\n",
    "\n",
    "idx_outliers = my_Hierarch.find_outliers_idx(max_clusters = 12, cluster_nums = [6, 7, 12])\n",
    "\n",
    "X_cleaned = X_uncleaned.drop(idx_outliers)\n",
    "Y_cleaned = [subseries for i, subseries in enumerate(Y_uncleaned) if i not in idx_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6623777c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ROC        RSI          EMA       MACD  MACD_signal  MACD_diff  \\\n",
      "0    -3.066849  49.792829   704.398068   3.215764     0.016586   3.199178   \n",
      "1   -11.654366  32.200984   661.444919 -26.389482   -15.822083 -10.567399   \n",
      "2   -18.477442  35.554372   620.317108 -15.357053   -19.332971   3.975918   \n",
      "3    -4.265466  49.254646   565.182666  -7.718505   -13.108627   5.390122   \n",
      "4    -0.607887  52.829282   567.738559   4.936302     3.968749   0.967554   \n",
      "..         ...        ...          ...        ...          ...        ...   \n",
      "684   7.026760  61.574883  2304.930564   8.272684     0.738220   7.534465   \n",
      "685  -2.643573  43.780738  2291.895486 -18.537858   -13.702638  -4.835220   \n",
      "686  -8.058747  35.022571  2266.157579 -19.488237   -19.019400  -0.468837   \n",
      "687  14.390147  74.074173  2324.648654  64.524922    37.793686  26.731236   \n",
      "688  15.663957  60.782539  2483.753710  41.962057    59.102522 -17.140466   \n",
      "\n",
      "            CCI  Bollinger_Mavg  Bollinger_hband  Bollinger_lband   Stoch_%K  \\\n",
      "0     56.329252      698.661111       730.866625       666.455598  68.088866   \n",
      "1   -196.425904      677.554167       754.144920       600.963414  17.535944   \n",
      "2    -64.939732      623.929167       716.786216       531.072118  32.304746   \n",
      "3     19.374880      570.053333       623.435614       516.671053  88.112252   \n",
      "4     80.943236      559.569167       599.566528       519.571805  85.761929   \n",
      "..          ...             ...              ...              ...        ...   \n",
      "684  110.693298     2323.158333      2406.454090      2239.862577  99.677679   \n",
      "685  -90.137146     2300.486111      2407.763593      2193.208629  26.717949   \n",
      "686 -108.636941     2267.908333      2387.687736      2148.128931  11.529412   \n",
      "687  285.416651     2292.763889      2469.466213      2116.061564  98.687281   \n",
      "688   48.704245     2469.194444      2758.518073      2179.870816  41.026043   \n",
      "\n",
      "      Stoch_%D  \n",
      "0    82.108555  \n",
      "1    12.568054  \n",
      "2    45.960133  \n",
      "3    85.310279  \n",
      "4    73.443477  \n",
      "..         ...  \n",
      "684  95.469908  \n",
      "685  36.247060  \n",
      "686  30.711041  \n",
      "687  97.819225  \n",
      "688  43.209392  \n",
      "\n",
      "[689 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_uncleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59e1dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 185 429 185\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_cleaned, Y_cleaned, test_size = 0.3, shuffle = False)\n",
    "print(len(X_train), len(X_test), len(Y_train), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0833be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9783783783783784\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=69)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
